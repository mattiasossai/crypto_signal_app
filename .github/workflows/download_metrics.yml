name: üì• Download & Commit metrics

on:
  workflow_dispatch:
  schedule:
    # t√§glich 05:00 UTC
    - cron: '0 5 * * *'

jobs:
  download:
    name: ‚¨áÔ∏è Download metrics | ${{ matrix.symbol }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        symbol: [BTCUSDT, ETHUSDT, BNBUSDT, SOLUSDT, XRPUSDT, ENAUSDT]
      max-parallel: 6

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Install unzip & curl
        run: sudo apt-get update && sudo apt-get install -y unzip curl

      - name: Download & extract metrics (Backfill)
        shell: bash
        run: |
          set -euo pipefail
          SYMBOL=${{ matrix.symbol }}
          YESTERDAY=$(date -I -d "yesterday")
          TARGET_DIR="data/futures/um/daily/metrics/${SYMBOL}"
          mkdir -p "$TARGET_DIR"

          # Backfill: ab Tag nach letztem CSV bis gestern
          if compgen -G "$TARGET_DIR/${SYMBOL}-metrics-*.csv" > /dev/null; then
            LAST=$(find "$TARGET_DIR" -type f -name "${SYMBOL}-metrics-*.csv" \
              | sed -E "s/.*${SYMBOL}-metrics-([0-9]{4}-[0-9]{2}-[0-9]{2})\.csv/\1/" \
              | sort | tail -n1)
            START=$(date -d "$LAST +1 day" '+%Y-%m-%d')
          else
            START="$YESTERDAY"
          fi
          END="$YESTERDAY"

          cur="$START"
          while [[ "$cur" < "$END" || "$cur" == "$END" ]]; do
            DATE="$cur"
            ZIP="${SYMBOL}-metrics-${DATE}.zip"
            URL="https://data.binance.vision/data/futures/um/daily/metrics/${SYMBOL}/${ZIP}"
            echo "‚Üí Fetching $ZIP"
            if curl -sSf "$URL" -o tmp.zip; then
              unzip -p tmp.zip > "$TARGET_DIR/${ZIP%.zip}.csv"
              rm tmp.zip
              echo " ‚úÖ extracted ${ZIP}"
            else
              echo " ‚ö†Ô∏è missing ${ZIP}"
              rm -f tmp.zip || true
            fi
            cur=$(date -I -d "$cur +1 day")
          done

      - name: Upload all metrics as single artifact
        uses: actions/upload-artifact@v4
        with:
          name: data-metrics
          path: |
            data/futures/um/daily/metrics/**/*.csv

  aggregate_and_push:
    name: Aggregate & Commit metrics Data
    needs: download
    runs-on: ubuntu-latest

    steps:
      - name: Checkout fresh
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Download metrics artifact
        uses: actions/download-artifact@v4
        with:
          name: data-metrics
          path: data-artifacts

      - name: Flatten into data-artifacts/data-metrics
        shell: bash
        run: |
          mkdir -p data-artifacts/data-metrics
          find data-artifacts -type f -name "*-metrics-*.csv" \
            -exec mv {} data-artifacts/data-metrics/ \;

      - name: Merge metrics into historical_tech
        shell: bash
        run: |
          set -euo pipefail
          mkdir -p historical_tech/metrics
          for file in data-artifacts/data-metrics/*.csv; do
            fname=$(basename "$file")
            symbol=${fname%%-*}                            # z.B. "BTCUSDT"
            dst="historical_tech/metrics/${symbol}/${fname}"
            mkdir -p "$(dirname "$dst")"
            mv "$file" "$dst"
            echo " ‚ûï $dst"
          done

      - name: Commit & Push metrics
        shell: bash
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git fetch origin main
          git reset --mixed origin/main
          git add historical_tech/metrics
          if git diff --cached --quiet; then
            echo "‚úÖ No new metrics to commit"
          else
            git commit -m "chore(data): backfill metrics ${START}‚Üí${END} [skip ci]"
            git push origin HEAD:main
          fi
