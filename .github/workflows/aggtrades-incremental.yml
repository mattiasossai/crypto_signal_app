# .github/workflows/aggtrades-incremental.yml
name: "4️⃣📥🛠️ aggTrades Inc. Download & Feat."

on:
  workflow_dispatch:
    inputs:
      start_date:
        description: 'Startdatum (YYYY-MM-DD)'
        required: false
      end_date:
        description: 'Enddatum (YYYY-MM-DD)'
        required: false
  schedule:
    - cron: '25 8 * * *'  # täglich 08:25 UTC

jobs:
  download-and-feature:
    name: "aggTrades ${{ matrix.symbol }} (incremental)"
    runs-on: ubuntu-latest
    strategy:
      matrix:
        symbol: [BTCUSDT, ETHUSDT, BNBUSDT, SOLUSDT, XRPUSDT, ENAUSDT]
      max-parallel: 1

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install --upgrade pandas pyarrow

      - name: Calc dates
        id: dates
        run: |
          echo "global_start=2025-01-01"       >> $GITHUB_OUTPUT
          echo "today=$(date -I -d 'yesterday')" >> $GITHUB_OUTPUT

      - name: Determine resume point
        id: resume
        run: |
          SYMBOL=${{ matrix.symbol }}
          DIR=features/aggTrades/${SYMBOL}
          mkdir -p "$DIR"
          LAST=$(ls $DIR/${SYMBOL}-features-*.parquet 2>/dev/null | sort | tail -n1 || true)
          if [[ -n "$LAST" ]]; then
            PREV_END=$(basename "$LAST" .parquet | sed -E 's/^.*_to_([0-9\-]+)$/\1/')
            START=$(date -I -d "$PREV_END + 1 day")
          else
            START=${{ steps.dates.outputs.global_start }}
          fi
          echo "start=$START" >> $GITHUB_OUTPUT
          echo "end=${{ steps.dates.outputs.today }}" >> $GITHUB_OUTPUT

      - name: Download & extract aggTrades (1-day overlap)
        run: |
          SYMBOL=${{ matrix.symbol }}
          SD=${{ steps.resume.outputs.start }}
          ED=${{ steps.resume.outputs.end }}
          case "$SYMBOL" in
            BTCUSDT|ETHUSDT) INC="2019-12-31";;
            XRPUSDT)         INC="2020-01-06";;
            BNBUSDT)         INC="2020-02-10";;
            SOLUSDT)         INC="2020-09-14";;
            ENAUSDT)         INC="2024-04-02";;
            *)               INC=$SD ;;
          esac
          [[ "$(date -d"$SD" +%s)" -lt "$(date -d"$INC" +%s)" ]] && SD="$INC"
          echo "→ Downloading aggTrades from $SD to $ED (1-day overlap)"
          TARGET="data/aggTrades/$SYMBOL"
          mkdir -p "$TARGET"
          CUR=$(date -I -d "$SD -1 day")
          while [[ "$CUR" < "$ED" || "$CUR" == "$ED" ]]; do
            ZIP="${SYMBOL}-aggTrades-${CUR}.zip"
            echo "→ Fetching $ZIP"
            if curl -sSf "https://data.binance.vision/data/futures/um/daily/aggTrades/$SYMBOL/$ZIP" -o "$ZIP"; then
              unzip -p "$ZIP" > "$TARGET/${ZIP%.zip}.csv"
              rm -f "$ZIP"
            else
              echo "⚠️ Missing $ZIP – skipping"
              rm -f "$ZIP"
            fi
            CUR=$(date -I -d "$CUR +1 day")
          done

      - name: Extract **only** the new day into tmp parquet
        run: |
          SYMBOL=${{ matrix.symbol }}
          TMP="features/aggTrades/${SYMBOL}/tmp_${SYMBOL}.parquet"
          python3 extract_aggTrades_features.py \
            --input-dir  data/aggTrades/${SYMBOL} \
            --start-date "${{ steps.resume.outputs.start }}" \
            --end-date   "${{ steps.resume.outputs.end }}" \
            --output-file "$TMP"

      - name: Append tmp to the existing Parquet (or create fresh)
        run: |
          SYMBOL=${{ matrix.symbol }}
          GS=${{ steps.dates.outputs.global_start }}
          NE=${{ steps.resume.outputs.end }}
          DIR=features/aggTrades/${SYMBOL}
          OUT="${DIR}/${SYMBOL}-features-${GS}_to_${NE}.parquet"
          mkdir -p "$DIR"
          OLD=$(ls $DIR/${SYMBOL}-features-${GS}_to_*.parquet 2>/dev/null | sort | tail -n1 || true)

          if [[ -n "$OLD" ]]; then
            python3 <<-'PYCODE'
import pandas as pd
import os, sys

old = pd.read_parquet(os.environ['OLD'])
new = pd.read_parquet(os.environ['DIR'] + '/tmp_' + os.environ['SYMBOL'] + '.parquet')
df = pd.concat([old, new]).sort_index()
df.to_parquet(os.environ['OUT'], compression='snappy')
PYCODE
            rm "$OLD"
          else
            mv "$DIR/tmp_${SYMBOL}.parquet" "$OUT"
          fi

      - name: Cleanup tmp & raw CSVs
        if: always()
        run: |
          rm -rf data/aggTrades/${{ matrix.symbol }}
          rm -f features/aggTrades/${{ matrix.symbol }}/tmp_*.parquet

      - name: Commit & Push merged Parquet
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add features/aggTrades/${{ matrix.symbol }}
          if git diff --cached --quiet; then
            echo "✔️ No new features to push"
          else
            git commit -m "♻️ ${{ matrix.symbol }} aggTrades-Features ${GS}→${NE}"
            git push https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }} HEAD:main
          fi
