# .github/workflows/aggtrades-incremental.yml
name: "4️⃣📥🛠️ aggTrades Inc. Download & Feat."

on:
  workflow_dispatch:
    inputs:
      start_date:
        description: 'Startdatum (YYYY-MM-DD)'
        required: true
      end_date:
        description: 'Enddatum (YYYY-MM-DD)'
        required: true
  schedule:
    - cron: '25 8 * * *'  # täglich 08:25 UTC

jobs:
  download-and-feature:
    name: "aggTrades ${{ matrix.symbol }} (incremental)"
    runs-on: ubuntu-latest
    strategy:
      matrix:
        symbol: [BTCUSDT, ETHUSDT, BNBUSDT, SOLUSDT, XRPUSDT, ENAUSDT]
      max-parallel: 1

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install --upgrade pandas pyarrow

      - name: Calculate dates
        id: dates
        run: |
          # globaler Startpunkt (fix für 2025)
          echo "global_start=2025-01-01" >> $GITHUB_OUTPUT
          # End = gestern
          echo "today=$(date -I -d 'yesterday')" >> $GITHUB_OUTPUT

      - name: Determine resume point
        id: resume
        run: |
          SYMBOL=${{ matrix.symbol }}
          DIR=features/aggTrades/${SYMBOL}
          # suche letzte Parquet
          last=$(ls $DIR/${SYMBOL}-features-*.parquet 2>/dev/null | sort | tail -n1 || true)
          if [[ -n "$last" ]]; then
            # extract end date
            prev_end=$(basename "$last" .parquet | sed -E 's/^.*_to_([0-9\-]+)$/\1/')
            start=$(date -I -d "$prev_end + 1 day")
          else
            start=${{ steps.dates.outputs.global_start }}
          fi
          echo "start=$start" >> $GITHUB_OUTPUT
          echo "end=${{ steps.dates.outputs.today }}" >> $GITHUB_OUTPUT

      - name: Download & unpack aggTrades (1-Day Overlap)
        shell: bash
        run: |
          SYMBOL=${{ matrix.symbol }}
          SD=${{ steps.resume.outputs.start }}
          ED=${{ steps.resume.outputs.end }}

          # Inception-Logik je Symbol
          case "$SYMBOL" in
            BTCUSDT|ETHUSDT) INC="2019-12-31";;
            XRPUSDT)         INC="2020-01-06";;
            BNBUSDT)         INC="2020-02-10";;
            SOLUSDT)         INC="2020-09-14";;
            ENAUSDT)         INC="2024-04-02";;
            *)               INC=$SD ;;
          esac
          [[ "$(date -d"$SD" +%s)" -lt "$(date -d"$INC" +%s)" ]] && SD="$INC"

          echo "→ Downloading aggTrades $SYMBOL from $SD to $ED (incl. overlap)"
          mkdir -p data/aggTrades/$SYMBOL
          CUR=$(date -I -d "$SD -1 day")
          while [[ "$CUR" <= "$ED" ]]; do
            ZIP="${SYMBOL}-aggTrades-${CUR}.zip"
            echo "→ Fetching $ZIP"
            if curl -sSf "https://data.binance.vision/data/futures/um/daily/aggTrades/$SYMBOL/$ZIP" -o "$ZIP"; then
              unzip -p "$ZIP" > data/aggTrades/"$SYMBOL"/"${ZIP%.zip}.csv"
              rm -f "$ZIP"
            else
              echo "⚠️ Missing $ZIP – skipping"
              rm -f "$ZIP"
            fi
            CUR=$(date -I -d "$CUR +1 day")
          done

      - name: Merge into Parquet & append
        shell: bash
        run: |
          set -euo pipefail

          SYMBOL=${{ matrix.symbol }}
          GS=${{ steps.dates.outputs.global_start }}
          NE=${{ steps.resume.outputs.end }}
          DIR=features/aggTrades/${SYMBOL}
          mkdir -p $DIR

          OLD=$DIR/${SYMBOL}-features-${GS}_to_*.parquet
          OUT=$DIR/${SYMBOL}-features-${GS}_to_${NE}.parquet

          # 1) erzeuge only-new in tmp
          TMP=$(mktemp --suffix=.parquet)
          python3 extract_aggTrades_features.py \
            --input-dir data/aggTrades/${SYMBOL} \
            --start-date "${{ steps.resume.outputs.start }}" \
            --end-date   "${NE}" \
            --output-file "$TMP"

          # 2) merge mit altem, lösche altes
          if compgen -G "$OLD" > /dev/null; then
            python3 - <<EOF
import pandas as pd
old = pd.read_parquet("$OLD")
new = pd.read_parquet("$TMP")
df  = pd.concat([old, new]).sort_index()
df.to_parquet("$OUT", compression="snappy")
EOF
            rm $OLD
          else
            mv $TMP $OUT
          fi
          rm -f $TMP

          git add $OUT

      - name: Commit & Push
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git checkout main
          git pull --rebase origin main
          git commit -m "♻️ ${{ matrix.symbol }} aggTrades features ${GS}→${NE}" || echo "No changes to commit"
          git push "https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}" HEAD:main

      - name: Cleanup raw CSVs
        if: always()
        run: rm -rf data/aggTrades/${{ matrix.symbol }}
