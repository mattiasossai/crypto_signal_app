name: 2ï¸âƒ£ðŸ“‚ Download & Commit indexPriceKlines (1h & 4h)

on:
  workflow_dispatch:
  schedule:
    # tÃ¤glich 08:00 UTC
    - cron: '10 8 * * *'

jobs:
  download:
    name: â¬‡ï¸ Download indexPriceKlines | ${{ matrix.symbol }}
    runs-on: ubuntu-latest
    strategy:
      matrix:
        symbol: [BTCUSDT, ETHUSDT, BNBUSDT, SOLUSDT, XRPUSDT, ENAUSDT]
      max-parallel: 6

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Install unzip & curl
        run: sudo apt-get update && sudo apt-get install -y unzip curl

      - name: Determine yesterday
        id: dates
        run: echo "END=$(date -I -d 'yesterday')" >> $GITHUB_ENV

      - name: Download & extract yesterdayâ€™s indexPriceKlines
        shell: bash
        run: |
          set -euo pipefail
          SYMBOL=${{ matrix.symbol }}
          DATE=$END
          for iv in 1h 4h; do
            BASE="data/futures/um/daily/indexPriceKlines/${SYMBOL}/${iv}"
            mkdir -p "$BASE"
            ZIP="${SYMBOL}-${iv}-${DATE}.zip"
            URL="https://data.binance.vision/data/futures/um/daily/indexPriceKlines/${SYMBOL}/${iv}/${ZIP}"
            echo "â†’ Fetching $ZIP"
            if curl -sSf "$URL" -o tmp.zip; then
              unzip -p tmp.zip > "$BASE/${ZIP%.zip}.csv"
              rm tmp.zip
            else
              rm -f tmp.zip || true
            fi
          done

      - name: Upload yesterdayâ€™s indexPriceKlines only
        uses: actions/upload-artifact@v4
        with:
          name: data-indexPriceKlines-${{ matrix.symbol }}
          path: |
            data/futures/um/daily/indexPriceKlines/${{ matrix.symbol }}/1h/${{ matrix.symbol }}-1h-${{ env.END }}.csv
            data/futures/um/daily/indexPriceKlines/${{ matrix.symbol }}/4h/${{ matrix.symbol }}-4h-${{ env.END }}.csv
          if-no-files-found: ignore

  aggregate_and_push:
    name: Aggregate & Commit indexPriceKlines Data
    needs: download
    runs-on: ubuntu-latest

    steps:
      - name: Checkout fresh
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Download all indexPriceKlines artifacts
        uses: actions/download-artifact@v4
        with:
          path: data-artifacts

      - name: Merge indexPriceKlines into historical_tech
        shell: bash
        run: |
          set -euo pipefail
          ROOT="historical_tech/indexPriceKlines/data-artifacts"
          mkdir -p "$ROOT"

          # verschiebe jede CSV einzeln, so gibt's keine "Directory not empty"-Konflikte
          find data-artifacts -type f -name '*.csv' | while read src; do
            # src = data-artifacts/data-indexPriceKlines-<SYMBOL>/<iv>/<file>.csv
            symbol_dir=$(basename "$(dirname "$(dirname "$src")")")   # data-indexPriceKlines-<SYMBOL>
            interval=$(basename "$(dirname "$src")")                 # 1h oder 4h
            file=$(basename "$src")
            dst="$ROOT/${symbol_dir}/${interval}/${file}"
            mkdir -p "$(dirname "$dst")"
            mv "$src" "$dst"
            echo " âž• $dst"
          done

      - name: Commit & Push indexPriceKlines
        shell: bash
        run: |
          git config user.name  "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git fetch origin main
          git reset --mixed origin/main
          git add historical_tech/indexPriceKlines/data-artifacts
          if git diff --cached --quiet; then
            echo "âœ… No new indexPriceKlines to commit"
          else
            git commit -m "chore(data): import indexPriceKlines ${END} [skip ci]"
            git push origin HEAD:main
          fi
