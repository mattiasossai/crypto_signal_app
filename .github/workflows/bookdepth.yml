# .github/workflows/bookdepth-incremental.yml
name: üõ†Ô∏è Daily BookDepth Incremental + Rolling Features

on:
  schedule:
    - cron: '0 7 * * *'
  workflow_dispatch: {}

jobs:
  bookdepth-incremental:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          persist-credentials: true

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: |
          pip install --upgrade pandas numpy scipy scikit-learn pyarrow parquet-tools

      - name: Run daily pipeline
        run: |
          python daily_bookdepth_pipeline.py

      - name: Sanity List updated columns
        run: |
          for F in features/bookDepth/*/*.parquet; do
            echo "---- $F ----"
            python3 -c "import pandas as pd; df = pd.read_parquet('$F'); print(df.tail(3))"
          done

      - name: Smoke-Test bookDepth
        run: |
          for FILE in features/bookDepth/*/*.parquet; do
            parquet-tools inspect "$FILE" \
              | grep -q "notional_imbalance_roll_7d" \
              || (echo "Missing notional_imbalance_roll_7d in $FILE" && exit 1)
            parquet-tools inspect "$FILE" \
              | grep -q "has_notional_imbalance_roll_7d" \
              || (echo "Missing has_notional_imbalance_roll_7d in $FILE" && exit 1)
            parquet-tools inspect "$FILE" \
              | grep -q "kyle_lambda_roll_30d" \
              || (echo "Missing kyle_lambda_roll_30d in $FILE" && exit 1)
          done

      - name: Commit & Push Parquets
        uses: EndBug/add-and-commit@v9
        with:
          add: 'features/bookDepth/**/*.parquet'
          message: '‚ôªÔ∏è BookDepth daily incremental + rolling features'
          author_name: ghactions
          author_email: actions@github.com
